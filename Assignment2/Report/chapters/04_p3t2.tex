\section{Part 3 Task 2}

\subsection{Simple Introduction}

In this part, I will train my RNN on palindrome dataset with input length $4$ and $19$, and let the RNN predict the last number of the palindrome number.

\subsection{Default Parameters}

\begin{itemize}
  \item \texttt{input\_length}: $19$, length of input sequence
  \item \texttt{input\_dim}: $1$, dimension of input data
  \item \texttt{num\_classes}: $10$, number of classes in the classification task
  \item \texttt{num\_hidden}: $128$, number of hidden units in the neural network
  \item \texttt{batch\_size}: $128$, batch size for training
  \item \texttt{learning\_rate}: $0.001$, learning rate for optimization
  \item \texttt{max\_epoch}: $1000$, maximum number of epochs to train the model
  \item \texttt{max\_norm}: $10$, maximum norm constraint for gradient clipping
  \item \texttt{data\_size}: $1000000$, size of the dataset
  \item \texttt{portion\_train}: $0.8$, portion of the dataset used for training
\end{itemize}

And I use \texttt{torch.optim.lr\_scheduler.StepLR()} (and step\_size=10, gamma=0.7) for scheduler, but it has some interesting unexpected influence.
Let me analysis it in the following part.

\subsection{Result Visualization}

Fig \ref{fig:p3_t=5} show a $T=5$ for RNN training, while fig \ref{fig:p3_t=20} show a $T=20$.

\begin{figure}[!htbp]
  \centering
  \begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=\textwidth]{img/Part3/RNN_train_t5.png}
    \caption{$T=5$ Normal Curve (without scheduler)}
  \end{subfigure}
  \begin{subfigure}[b]{1\textwidth}
    \includegraphics[width=\textwidth]{img/Part3/RNN_train_t5_fail.png}
    \caption{$T=5$ Fail Curve (with scheduler)}
  \end{subfigure}
  \caption{$T=5$ Curves}
  \label{fig:p3_t=5}
\end{figure}

\subsection{Result Analysis}

Through actual operations, I discovered a very strange situation: when training with $T=5$, 100\% accuracy can be achieved without the scheduler.
After using the scheduler, this increase becomes very slow; on the contrary, in $ When T=20$, not using the scheduler will cause the model to degrade, but using it will keep the model 100\% accurate.

I compare the training success and ``failure'' curves together and guess some possible reasons.

\begin{itemize}
  \item {First, analyze $T=5$. We know that \texttt{StepLR} can multiply the learning rate with $\gamma$ after a certain steps.
      This multiplication may cause an exponential explosion after several times, and the learning rate gradually drops to a very small value.
      Observing the normal curve without scheduler, we can find that the model reaches perfect accuracy after about 150 epochs.
      Therefore, if a scheduler is used, the model will not be able to effectively complete learning within a certain epoch, resulting in lower accuracy.
      But the learning rate still increased until the end.
    }

  \item {Second, for $T=20$, why does the accuracy become higher after using the scheduler?
      Observing the failure curve which without using the scheduler, we can find that the accuracy of the model reached a very high value at the beginning,
      but as the training continued, the accuracy experienced several sudden drops, and loss also appeared corresponding rising.
      My guess is that during the training process, it achieved very high accuracy at the beginning, but it did not perform a early stop, and gradient explosion occurred later.
      Although I used \texttt{clip\_grad\_norm\_()} correctly, it may be that the value of norm is too high, making it increasingly difficult to correct gradient explosion problem.
      Moreover, with the vanishing gradient problem caused by long dependencies of RNN, this makes correct learning more difficult.
      The use of the scheduler may have corrected this unexpected:
      after the epoch rises and before the gradient explosion occurs, the learning rate has been reduced to a very low value, simulating a early stop,
      so the impact of the gradient explosion has become very small, make it getting rid of significantly affect the entire model.
    }
\end{itemize}

Of course, the above is just guess which is not rigorous.
Usually, in general, we will find that when the input length is low, RNN can eventually achieve a higher result, but once the input length becomes longer, its accuracy is very easy to decline.
As the training continued, the model may seriously degrade.
This can reflect a characteristic of RNN: the model's ability of memory is not very good. Once the input dependencies become longer, the problem of vanishing gradient occurs during training, which leads to poor learning results.
The model will become very poor.

So in comparison, maybe using LSTM is a good choice.
