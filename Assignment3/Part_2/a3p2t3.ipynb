{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "30e30f5f6acaab47",
            "metadata": {},
            "source": [
                "## Global Setting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5bf5404101cdc4e",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-05-23T09:12:04.185140Z",
                    "start_time": "2024-05-23T09:12:04.172137Z"
                }
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "# True if you want to get dynamic output in notebook block, else False\n",
                "SHOW_IMG_IN_BLOCK:bool = True\n",
                "\n",
                "MODEL_PATH:str = './model/mnist_generator_final.pt'\n",
                "IMAGE_OUT_PATH:str = './images/t3/'\n",
                "\n",
                "# True if you want to get single images for each step, else False\n",
                "NEED_EACH_STEP_IMG:bool = False\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b923e1d4ff34d89e",
            "metadata": {},
            "source": [
                "### Load the Model, Prepare Noise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2bdf58dc49f5011b",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-05-23T09:12:04.262137Z",
                    "start_time": "2024-05-23T09:12:04.189139Z"
                }
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "from torchvision.utils import save_image\n",
                "from my_gan import Generator\n",
                "\n",
                "generator: Generator = Generator(100).to(DEVICE)\n",
                "generator.load_state_dict(torch.load(MODEL_PATH))\n",
                "generator.eval()\n",
                "\n",
                "noise_begin: torch.Tensor = torch.randn(size=(1, 100), device=DEVICE)\n",
                "noise_end: torch.Tensor = torch.randn(size=(1, 100), device=DEVICE)\n",
                "\n",
                "noises_interp: list[torch.Tensor] = []\n",
                "steps: int = 9\n",
                "for i in range(steps):\n",
                "    alpha = i / (steps - 1)\n",
                "    noise = noise_begin * (1 - alpha) + noise_end * alpha\n",
                "    noises_interp.append(noise)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7aab0f504eed3d2",
            "metadata": {},
            "source": [
                "### Generate and Save Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bcd10fdda5c67123",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-05-23T09:12:04.293243Z",
                    "start_time": "2024-05-23T09:12:04.264138Z"
                }
            },
            "outputs": [],
            "source": [
                "noises_tensor: torch.Tensor = torch.stack(noises_interp).squeeze()\n",
                "\n",
                "if NEED_EACH_STEP_IMG:\n",
                "    for i in range(steps):\n",
                "        img_data: torch.Tensor = generator(noises_tensor[i].view(1, 100))\n",
                "        img_gen: torch.Tensor = img_data.view(1, 28, 28)\n",
                "        save_image(img_gen, f'{IMAGE_OUT_PATH}step_{i}.png', normalize=True, value_range=(-1, 1))\n",
                "\n",
                "img_data: torch.Tensor = generator(noises_tensor)\n",
                "img_gen: torch.Tensor = img_data.view(img_data.shape[0], 1, 28, 28)\n",
                "save_image(img_gen, f'{IMAGE_OUT_PATH}whole_latest.png', nrow=steps, normalize=True, value_range=(-1, 1))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "26eca152bb258164",
            "metadata": {},
            "source": [
                "### Show Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fde168765364b16f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import display, Image\n",
                "\n",
                "if SHOW_IMG_IN_BLOCK:\n",
                "    print(f'Show latest image steps')\n",
                "    display(Image(filename=f'{IMAGE_OUT_PATH}whole_latest.png'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "261e4c84864ad861",
            "metadata": {},
            "source": [
                "### Static Show Prepared Results\n",
                "\n",
                "![whole1](../Report/img/p2t3/whole1.png)\n",
                "\n",
                "![whole2](../Report/img/p2t3/whole2.png)\n",
                "\n",
                "![whole3](../Report/img/p2t3/whole3.png)\n",
                "\n",
                "![whole4](../Report/img/p2t3/whole4.png)\n",
                "\n",
                "![whole5](../Report/img/p2t3/whole5.png)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 2
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython2",
            "version": "2.7.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}